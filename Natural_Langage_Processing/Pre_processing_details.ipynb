{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE - PROCESSING TUTORIAL \n",
    "\n",
    "Cleaning and preparing text data for use in a specific context (ultimate goal is to reduce the text to only the words that you need for your NLP goals)\n",
    "Removes noise from data.\n",
    "\n",
    "While this list is not exhaustive, we will cover a few common approaches for cleaning and processing text data. They include:\n",
    "\n",
    "    . Using Regex & NLTK libraries\n",
    "    . Removing unnecessary characters and formatting\n",
    "    . Tokenization – break multi-word strings into smaller components\n",
    "    . Normalization – a catch-all term for processing data; this includes stemming and lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
